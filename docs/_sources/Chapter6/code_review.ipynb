{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a4b708",
   "metadata": {},
   "source": [
    "## Code Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165f17d",
   "metadata": {},
   "source": [
    "This section covers some tools to automatically review and improve your code such as sorting imports, checking for missing docstrings, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4451544",
   "metadata": {},
   "source": [
    "### isort: Automatically Sort your Python Imports in 1 Line of Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ab924",
   "metadata": {},
   "source": [
    "As your codebase expands, you may find yourself importing numerous libraries, which can become overwhelming to navigate. To avoid arranging your imports manually, use isort.\n",
    "\n",
    "isort is a Python library that automatically sorts imports alphabetically, grouping them by section and type. \n",
    "\n",
    "Consider the following example where your imports are unsorted:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4949e",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import confusion_matrix, fl_score, classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "```\n",
    "By running `isort name_of_your_file.py`, isort can sort your imports automatically into the following:\n",
    "\n",
    "```python\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, fl_score,\n",
    "                             roc_curve)\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedKFold,\n",
    "                                     TimeSeriesSplit, train_test_split)\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7beb1d",
   "metadata": {},
   "source": [
    "You can use isort with pre-commit by adding the following to your .pre-commit-config.yaml file:\n",
    "\n",
    "```yaml\n",
    "-   repo: https://github.com/timothycrosley/isort\n",
    "    rev: 5.12.0\n",
    "    hooks:\n",
    "    -   id: isort\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5850a",
   "metadata": {},
   "source": [
    "[Link to isort](https://github.com/pycqa/isort)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba323cbd",
   "metadata": {},
   "source": [
    "### interrogate: Check your Python Code for Missing Docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844a21a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install interrogate  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f1de",
   "metadata": {},
   "source": [
    "Sometimes, you might forget to include docstrings for classes and functions. Instead of manually searching through all your functions and classes for missing docstrings, use interrogate.\n",
    "\n",
    "Consider the following example where there are missing docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile interrogate_example.py\n",
    "class Math:\n",
    "    def __init__(self, num) -> None:\n",
    "        self.num = num\n",
    "\n",
    "    def plus_two(self):\n",
    "        \"\"\"Add 2\"\"\"\n",
    "        return self.num + 2\n",
    "\n",
    "    def multiply_three(self):\n",
    "        return self.num * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c1052",
   "metadata": {},
   "source": [
    "You can use interrogate to identify missing docstrings:\n",
    "```bash\n",
    "interrogate interrogate_example.py\n",
    "```\n",
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a4add",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "!interrogate interrogate_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89eb02f",
   "metadata": {},
   "source": [
    "You can use interrogate with pre-commit by adding the following to your .pre-commit-config.yaml file:\n",
    "```yaml\n",
    "- repo: https://github.com/pre-commit/mirrors-interrogate\n",
    "  rev: v1.4.0\n",
    "  hooks:\n",
    "  - id: interrogate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c4722",
   "metadata": {},
   "source": [
    "[Link to interrogate](https://interrogate.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537f1b3",
   "metadata": {},
   "source": [
    "### mypy: Static Type Checker for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8590b8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install mypy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c341f",
   "metadata": {},
   "source": [
    "Type hinting in Python is useful for other developers to understand the expected data types to be used in your functions. To automate type checking in your code, use mypy. \n",
    "\n",
    "Consider the following file that includes type hinting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd54220",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mypy_example.py\n",
    "from typing import List, Union\n",
    "\n",
    "def get_name_price(fruits: list) -> Union[list, tuple]:\n",
    "    return zip(*fruits)\n",
    "\n",
    "fruits = [('apple', 2), ('orange', 3), ('grape', 2)]\n",
    "names, prices = get_name_price(fruits)\n",
    "print(names)  # ('apple', 'orange', 'grape')\n",
    "print(prices)  # (2, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d434389",
   "metadata": {},
   "source": [
    "When typing the following command on your terminal:\n",
    "```bash\n",
    "mypy mypy_example.py\n",
    "```\n",
    "you will get the output similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8bc8b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!mypy mypy_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f806da",
   "metadata": {},
   "source": [
    "You can use mypy with pre-commit by adding the following to your .pre-commit-config.yaml file:\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "- repo: https://github.com/pre-commit/mirrors-mypy\n",
    "  rev: v0.910\n",
    "  hooks:\n",
    "  - id: mypy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e5471",
   "metadata": {},
   "source": [
    "[Link to mypy](https://mypy.readthedocs.io/en/latest/introduction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a2597",
   "metadata": {},
   "source": [
    "### Refurb: Refurbish and Modernize Python Codebases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac43749",
   "metadata": {},
   "source": [
    "If you want to have some guidelines to improve and optimize your code, try Refurb.\n",
    "\n",
    "For example, if you have a file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626061b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_refurb.py\n",
    "for n in [1, 2, 3, 4]:\n",
    "    if n == 2 or n == 4:\n",
    "        res = n/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35499621",
   "metadata": {},
   "source": [
    "You can use Refurb to refurbish your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d0d7ee",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ refurb test_refurb.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edef906",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!refurb test_refurb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bcbc5f",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ refurb test_refurb.py --explain FURB109\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466dce55",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!refurb test_refurb.py --explain FURB109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d139e3f",
   "metadata": {},
   "source": [
    "Refurb only works with Python 3.10 and above.\n",
    "\n",
    "You can use Refurb with pre-commit by adding the following to your .pre-commit-config.yaml file:\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "  - repo: https://github.com/dosisod/refurb\n",
    "    rev: REVISION\n",
    "    hooks:\n",
    "      - id: refurb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b25c77",
   "metadata": {},
   "source": [
    "[Link to Refurb](https://github.com/dosisod/refurb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39aed16",
   "metadata": {},
   "source": [
    "### eradicate: Remove Junk Comments from Python Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e00646",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install eradicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b508f",
   "metadata": {},
   "source": [
    "Outdated or unused code left as comments in Python files can clutter codebases, making them harder to read and maintain. \n",
    "\n",
    "Eradicate solves this by automatically identifying and removing commented-out code from Python files.\n",
    "\n",
    "Let's see eradicate in action:\n",
    "\n",
    "Example Python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile eradicate_test.py\n",
    "# from math import *\n",
    "\n",
    "def mean(nums: list):\n",
    "    # print(nums)\n",
    "    # TODO: check if nums is empty\n",
    "    # Return mean\n",
    "    return sum(nums) / len(nums)\n",
    "\n",
    "# nums = [0, 1]\n",
    "nums = [1, 2, 3]\n",
    "mean(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416d290",
   "metadata": {},
   "source": [
    "Preview changes:\n",
    "\n",
    "```bash\n",
    "$ eradicate eradicate_test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc55e68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!eradicate eradicate_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fe43d",
   "metadata": {},
   "source": [
    "Apply changes:\n",
    "\n",
    "```bash\n",
    "$ eradicate eradicate_test.py -i\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3601e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!eradicate eradicate_test.py -i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494e7f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d501e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# show file contents\n",
    "%cat eradicate_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fbcfb",
   "metadata": {},
   "source": [
    "In this example, eradicate removes:\n",
    "\n",
    "1. The commented-out import statement `# from math import *`\n",
    "2. The commented-out debug print statement `# print(nums)`\n",
    "3. The commented-out variable assignment `# nums = [0, 1]`\n",
    "\n",
    "However, it preserves the meaningful comments:\n",
    "\n",
    "1. The TODO comment `# TODO: check if nums is empty`\n",
    "2. The descriptive comment `# Return mean`\n",
    "\n",
    "This cleanup improves the code's readability by removing distracting, unused code comments while keeping important notes for developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31760b3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "You can use eradicate with pre-commit by adding the following to your `.pre-commit-config.yaml` file:\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "- repo: https://github.com/wemake-services/eradicate/\n",
    "  rev: v2.2.0\n",
    "  hooks:\n",
    "  - id: eradicate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c814c",
   "metadata": {},
   "source": [
    "[Link to eradicate](https://github.com/wemake-services/eradicate/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10256a",
   "metadata": {},
   "source": [
    "### Pydantic: Enforce Data Types on Your Function Parameters at Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc3979",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce49e3",
   "metadata": {},
   "source": [
    "To enforce data types and validate function parameters at runtime, use Pydantic. \n",
    "\n",
    "Pydantic will attempt to convert values to the correct data type. If the conversion fails, it raises a ValidationError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "\n",
    "class SplitConfig(BaseModel):\n",
    "    test_size: float = 0.3\n",
    "    random_state: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57410ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, config: SplitConfig = SplitConfig()):\n",
    "    test_size = config.test_size\n",
    "    random_state = config.random_state\n",
    "    ...\n",
    "\n",
    "\n",
    "split_data(SplitConfig(random_state=1.0)) \n",
    "# --> 1 (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(SplitConfig(random_state=\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a5d52",
   "metadata": {},
   "source": [
    "[Link to Pydantic](https://docs.pydantic.dev/).\n",
    "\n",
    "[Build a full-stack ML application with Pydantic and Prefect](https://towardsdatascience.com/build-a-full-stack-ml-application-with-pydantic-and-prefect-915f00fe0c62?sk=b1f8c5cb53a6a9d7f48d66fa778e9cf0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f9891",
   "metadata": {},
   "source": [
    "### perfplot: Performance Analysis for Python Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559ab20",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install perfplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f99e94",
   "metadata": {},
   "source": [
    "If you want to compare the performance between different snippets and plot the results, use perfplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfplot\n",
    "\n",
    "\n",
    "def append(n):\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(i)\n",
    "    return l\n",
    "\n",
    "\n",
    "def comprehension(n):\n",
    "    return [i for i in range(n)]\n",
    "\n",
    "\n",
    "def list_range(n):\n",
    "    return list(range(n))\n",
    "\n",
    "\n",
    "perfplot.show(\n",
    "    setup=lambda n: n,\n",
    "    kernels=[\n",
    "        append,\n",
    "        comprehension,\n",
    "        list_range,\n",
    "    ],\n",
    "    n_range=[2**k for k in range(25)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48074485",
   "metadata": {},
   "source": [
    "[Link to perfplot](https://github.com/nschloe/perfplot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0f2fe",
   "metadata": {},
   "source": [
    "### Analyze the Memory Usage of Your Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5699",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297389d6",
   "metadata": {},
   "source": [
    "If you want to analyze the memory consumption of your Python code line-by-line, use memory_profiler. This package allows you to generate a full memory usage report of your executable and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile memory_profiler_test.py \n",
    "from memory_profiler import profile\n",
    "\n",
    "\n",
    "@profile\n",
    "def func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23957b55",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mprof run memory_profiler_test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02eb5b5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!mprof run memory_profiler_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf295ff",
   "metadata": {},
   "source": [
    "Plot the memory usage:\n",
    "```bash\n",
    "$ mprof plot\n",
    "```\n",
    "![](../img/memory_profiler.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e665d",
   "metadata": {},
   "source": [
    "[Link to memory_profiler](https://github.com/pythonprofilers/memory_profiler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08cb4a",
   "metadata": {},
   "source": [
    "### Vulture: Automatically Find Dead Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d6fbc",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install vulture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c2e70",
   "metadata": {},
   "source": [
    "Unused code poses multiple issues, including:\n",
    "\n",
    "- Increased difficulty in comprehending the code.\n",
    "- Challenges in debugging and testing.\n",
    "- Unnecessary consumption of memory and resources.\n",
    "\n",
    "To automatically remove unused Python code, use Vulture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dead_code.py\n",
    "# Unused Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def clean_data(self):\n",
    "        # Unused Variables\n",
    "        how = 'all'\n",
    "        inplace = True \n",
    "\n",
    "        # Data cleaning logic here\n",
    "        self.data = self.data.dropna(how='any', inplace=False)\n",
    "\n",
    "    def get_mean(self):\n",
    "        # This method is defined but not used in the class\n",
    "        return self.data.mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.DataFrame({'A': [1, 2, None, 4]})\n",
    "    \n",
    "    processor = DataProcessor(data)\n",
    "    processor.clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca56bd2",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ vulture dead_code.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10c3ee",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "!vulture dead_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16a09e",
   "metadata": {},
   "source": [
    "You can use Vulture with pre-commit by adding the following to your .pre-commit-config.yaml file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db20f43c",
   "metadata": {},
   "source": [
    "```yaml\n",
    "repos:\n",
    "  - repo: https://github.com/jendrikseipp/vulture\n",
    "    rev: 'v2.3'  # or any later Vulture version\n",
    "    hooks:\n",
    "      - id: vulture\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af060e8",
   "metadata": {},
   "source": [
    "[Link to Vulture](https://github.com/jendrikseipp/vulture)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bf297",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "### Beartype: Fast, Efficient Runtime Type Checking for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11cef98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install beartype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06994b92",
   "metadata": {},
   "source": [
    "Static type checkers like mypy perform type checking only during development/compile time. This means that type errors may not be caught until runtime, potentially causing issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de6eb2",
   "metadata": {},
   "source": [
    "Let's consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fca6bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile typehint.py\n",
    "def calculate_statistics(data: list[float]) -> dict[str, float]:\n",
    "    return {\n",
    "        \"mean\": sum(data) / len(data),\n",
    "        \"first\": data[0]\n",
    "    }\n",
    "\n",
    "numbers = [1, \"a\", 3]  # mypy error, but code will run\n",
    "result = calculate_statistics(numbers)  # Fails at runtime during sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101d31a",
   "metadata": {},
   "source": [
    "Running mypy on this code will raise an error, but the code will still run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710ffd3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "!mypy typehint.py # mypy error, but code will run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6883c8b",
   "metadata": {},
   "source": [
    "However, running the code will raise a TypeError at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b58dac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "!python typehint.py # Fails at runtime during sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26aca4e",
   "metadata": {},
   "source": [
    "Beartype is a runtime type checker that enhances type safety by performing type verification at runtime. This catches issues that static analysis might overlook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7071975",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from beartype import beartype\n",
    "\n",
    "@beartype\n",
    "def calculate_statistics(data: list[float]) -> dict[str, float]:\n",
    "    return {\n",
    "        \"mean\": sum(data) / len(data),\n",
    "        \"first\": data[0]\n",
    "    }\n",
    "\n",
    "# Fast runtime checking with clear errors\n",
    "numbers = [1, \"a\", 3]\n",
    "result = calculate_statistics(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e9489",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Pydantic is another popular library for runtime type checking. However, it adds overhead during model creation and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf256822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class StatisticsInput(BaseModel):\n",
    "    data: List[float]\n",
    "\n",
    "class StatisticsOutput(BaseModel):\n",
    "    mean: float\n",
    "    first: float\n",
    "\n",
    "def calculate_statistics(input_data: StatisticsInput) -> StatisticsOutput:\n",
    "    return StatisticsOutput(\n",
    "        mean=sum(input_data.data) / len(input_data.data),\n",
    "        first=input_data.data[0]\n",
    "    )\n",
    "\n",
    "# Validates during model creation, but adds overhead\n",
    "numbers = [1, \"a\", 3]\n",
    "input_model = StatisticsInput(data=numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12eb0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Beartype offers efficient runtime type checking with constant time complexity. Its dynamic wrappers around functions and methods enable flexible and efficient type-checking, making it a great choice for ensuring type safety in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249724d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "[Link to Beartype](https://github.com/beartype/beartype)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   20,
   24,
   32,
   57,
   68,
   72,
   76,
   80,
   86,
   98,
   106,
   110,
   120,
   124,
   128,
   132,
   138,
   149,
   157,
   161,
   173,
   177,
   181,
   187,
   192,
   196,
   202,
   206,
   212,
   216,
   230,
   234,
   238,
   242,
   252,
   265,
   273,
   277,
   285,
   291,
   295,
   304,
   319,
   331,
   335,
   339,
   343,
   349,
   358,
   369,
   371,
   377,
   381,
   385,
   389,
   417,
   421,
   425,
   429,
   433,
   448,
   454,
   458,
   466,
   470,
   474,
   478,
   488,
   515,
   521,
   525,
   529,
   539,
   543,
   547,
   555,
   559,
   563,
   578,
   582,
   589,
   594,
   601,
   605,
   625,
   629,
   651,
   655
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}