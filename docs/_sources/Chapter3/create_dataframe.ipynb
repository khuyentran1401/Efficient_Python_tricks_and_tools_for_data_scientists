{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa52513e",
   "metadata": {},
   "source": [
    "## Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819c111",
   "metadata": {},
   "source": [
    "This section shows some tips to read or create a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d0fbcf",
   "metadata": {},
   "source": [
    "### Leverage PyArrow for Efficient Parquet Data Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb006",
   "metadata": {},
   "source": [
    "When dealing with Parquet files in pandas, it is common to first load the data into a pandas DataFrame and then apply filters.\n",
    "\n",
    "To improve query execution speed, push down the filers to the PyArrow engine to leverage PyArrow's processing optimizations.\n",
    "\n",
    "In the following code, filtering a dataset of 100 million rows using PyArrow is approximately 113 times faster than performing the same operation with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4027e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"data.parquet\"\n",
    "\n",
    "# Define the number of rows\n",
    "num_rows = 100_000_000\n",
    "\n",
    "# Generate the DataFrame\n",
    "data = {\"id\": range(1, num_rows + 1), \"price\": np.random.rand(num_rows) * 100}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the result to a Parquet file\n",
    "df.to_parquet(file_path, index=False, row_group_size=2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "pd.read_parquet(file_path).query(\"id == 50000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd15a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "pd.read_parquet(file_path, filters=[(\"id\", \"=\", 50000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d9c00",
   "metadata": {},
   "source": [
    "### Fix Unnamed:0 When Reading a CSV in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b6b3e",
   "metadata": {},
   "source": [
    "Sometimes, when reading a CSV in pandas, you will get an `Unnamed:0` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc837f53",
   "metadata": {},
   "source": [
    " To fix this, add `index_col=0` to `pandas.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54558cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1463b1",
   "metadata": {},
   "source": [
    "### Read Data from a Website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ce0a2",
   "metadata": {},
   "source": [
    "pandas allows you to read data from a website without downloading the data. \n",
    "\n",
    "For example, to read a CSV from GitHub, click Raw then copy the link. \n",
    "\n",
    "![](../img/github_raw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/exercise.csv\",\n",
    "    index_col=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8193757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514655ef",
   "metadata": {},
   "source": [
    "### Divide a Large pandas DataFrame into Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ad173",
   "metadata": {},
   "source": [
    "Large dataframes can consume a significant amount of memory. By processing data in smaller chunks, you can avoid running out of memory and access data faster.\n",
    "\n",
    "In the code below, using `chunksize=100000` is approximately 5495 times faster than not using `chunksize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "pd.read_csv(\"../data/flight_data_2018_to_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84214a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/flight_data_2018_to_2022.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "pd.read_csv(\"../data/flight_data_2018_to_2022.csv\", chunksize=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac201d0a",
   "metadata": {},
   "source": [
    "We can see that using `chunksize=100000` divides the DataFrame into 6 portions, 5 of which have 100000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(\"../data/flight_data_2018_to_2022.csv\", chunksize=100000)\n",
    "for df_ in df_chunks:\n",
    "    print(df_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36ca41",
   "metadata": {},
   "source": [
    "### Read HTML Tables Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbead3bc",
   "metadata": {},
   "source": [
    "If you want to quickly extract a table on a website and turn it into a Pandas DataFrame, use `pd.read_html`. In the code below, I extracted the table from a Wikipedia page in one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea35f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/Poverty\")\n",
    "df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7088ab",
   "metadata": {},
   "source": [
    "### DataFrame.copy(): Make a Copy of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21ba7f",
   "metadata": {},
   "source": [
    "Have you ever tried to make a copy of a DataFrame using `=`? You will not get a copy but a reference to the original DataFrame. Thus, changing the new DataFrame will also change the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06209232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"col1\": [1, 2, 3], \"col2\": [4, 5, 6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e740c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2[\"col1\"] = [7, 8, 9]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbced835",
   "metadata": {},
   "source": [
    "A better way to make a copy is to use `df.copy()`. Now, changing the copy will not affect the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": [1, 2, 3], \"col2\": [4, 5, 6]})\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df3 = df.copy()\n",
    "\n",
    "# Change the value of the copy\n",
    "df3[\"col1\"] = [7, 8, 9]\n",
    "\n",
    "# Check if the original DataFrame has been changed\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e48ba",
   "metadata": {},
   "source": [
    "### Copy on Write Mode in pandas 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e549de8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pandas==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf4708",
   "metadata": {},
   "source": [
    "pandas DataFrame returns a view by default when selecting a subset, meaning changes to the view will change the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"col1\": [1, 2], \"col2\": [3, 4]})\n",
    "\n",
    "# Create a view of the original DataFrame\n",
    "df2 = df1[\"col1\"]\n",
    "\n",
    "# Change the value of the view\n",
    "df2.iloc[0] = 10\n",
    "\n",
    "# The original DataFrame has been changed\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95ae48",
   "metadata": {},
   "source": [
    "pandas 2.0 offers the option to return a copy instead of a view by default, preventing changes to the copy from affecting the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "df1 = pd.DataFrame({\"col1\": [1, 2], \"col2\": [3, 4]})\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df2 = df1[\"col1\"]\n",
    "\n",
    "# Change the value of the copy\n",
    "df2.iloc[0] = 10\n",
    "\n",
    "# The original DataFrame has not been changed\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e6c3f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a sample CSV file\n",
    "data = {\n",
    "    \"start_date\": [datetime.now() - timedelta(days=i) for i in range(5)],\n",
    "    \"end_date\": [datetime.now() - timedelta(days=i - 1) for i in range(5)],\n",
    "    \"value\": [100, 200, 300, 400, 500],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3acd370",
   "metadata": {},
   "source": [
    "### Specify Datetime Columns with parse_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdcb569",
   "metadata": {},
   "source": [
    "Use the `parse_dates` parameter to specify datetime columns when creating a pandas DataFrame from a CSV, rather than converting columns to datetime post-creation. This keeps the code concise and easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of this\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(f'Datatypes before converting to datetime\\n{df.dtypes}\\n')\n",
    "\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "print(f'Datatypes after converting to datetime\\n{df.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this\n",
    "df = pd.read_csv('data.csv', parse_dates=['start_date', 'end_date'])\n",
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   20,
   24,
   32,
   49,
   54,
   57,
   61,
   65,
   73,
   78,
   82,
   85,
   89,
   97,
   106,
   108,
   112,
   118,
   125,
   130,
   135,
   138,
   142,
   146,
   150,
   154,
   159,
   163,
   167,
   174,
   178,
   182,
   193,
   197,
   201,
   205,
   218,
   222,
   237,
   253,
   257,
   261,
   273
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}