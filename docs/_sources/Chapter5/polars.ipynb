{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e594489e",
   "metadata": {},
   "source": [
    "## Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc3800",
   "metadata": {},
   "source": [
    "### Polars: Blazing Fast DataFrame Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c04f9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d43e0",
   "metadata": {},
   "source": [
    "If you want data manipulation library that's both fast and memory-efficient, try Polars. Polars provides a high-level API similar to Pandas but with better performance for large datasets.\n",
    "\n",
    "The code below compares the performance of Polars and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create two Pandas DataFrames with 1 million rows each\n",
    "pandas_df1 = pd.DataFrame({\n",
    "    'key': np.random.randint(0, 1000, size=1_000_000),\n",
    "    'value1': np.random.rand(1_000_000)\n",
    "})\n",
    "\n",
    "pandas_df2 = pd.DataFrame({\n",
    "    'key': np.random.randint(0, 1000, size=1_000_000),\n",
    "    'value2': np.random.rand(1000000)\n",
    "})\n",
    "\n",
    "# Create two Polars DataFrames from the Pandas DataFrames\n",
    "polars_df1 = pl.from_pandas(pandas_df1)\n",
    "polars_df2 = pl.from_pandas(pandas_df2)\n",
    "\n",
    "# Merge the two DataFrames on the 'key' column\n",
    "start_time = time.time()\n",
    "pandas_merged = pd.merge(pandas_df1, pandas_df2, on='key')\n",
    "pandas_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "polars_merged = polars_df1.join(polars_df2, on='key')\n",
    "polars_time = time.time() - start_time\n",
    "\n",
    "print(f\"Pandas time: {pandas_time:.6f} seconds\")\n",
    "print(f\"Polars time: {polars_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222007ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Polars is {pandas_time/polars_time:.2f} times faster than Pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c275293",
   "metadata": {},
   "source": [
    "[Link to polars](https://github.com/pola-rs/polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0611b4e",
   "metadata": {},
   "source": [
    "### Polars: Speed Up Data Processing 12x with Lazy Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc330aa2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033750a2",
   "metadata": {},
   "source": [
    "Polars is a lightning-fast DataFrame library that utilizes all available cores on your machine. \n",
    "\n",
    "Polars has two APIs: an eager API and a lazy API.\n",
    "\n",
    "The eager execution is similar to Pandas, which executes code immediately. \n",
    "\n",
    "In contrast, the lazy execution defers computations until the `collect()` method is called. This approach avoids unnecessary computations, making lazy execution potentially more efficient than eager execution.\n",
    "\n",
    "The code following code shows filter operations on a DataFrame containing 10 million rows. Running polars with lazy execution is 12 times faster than using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760966b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows in the dataset\n",
    "num_rows = 10_000_000\n",
    "\n",
    "# Sample data for categorical columns\n",
    "categories = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "# Generate random data for the dataset\n",
    "data = {\n",
    "    \"Cat1\": np.random.choice(categories, size=num_rows),\n",
    "    \"Cat2\": np.random.choice(categories, size=num_rows),\n",
    "    \"Num1\": np.random.randint(1, 100, size=num_rows),\n",
    "    \"Num2\": np.random.randint(1000, 10000, size=num_rows),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc88514",
   "metadata": {},
   "source": [
    "Create a pandas DataFrame and filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90734076",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df[(df['Cat1'] == 'a') & (df['Cat2'] == 'b') & (df['Num1'] >= 70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abbd43",
   "metadata": {},
   "source": [
    "Create a polars DataFrame and filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl_df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46df432",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_df.lazy().filter((pl.col('Cat1') == 'a') & (pl.col('Cat2') == 'b') & (pl.col('Num1') >= 70)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706bd4b",
   "metadata": {},
   "source": [
    "[Link to polars](https://github.com/pola-rs/polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5bf18d",
   "metadata": {},
   "source": [
    "### Polars vs. Pandas for CSV Loading and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ab82a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9979495",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!wget -O airport-codes.csv \"https://datahub.io/core/airport-codes/r/0.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886877d4",
   "metadata": {},
   "source": [
    "The `read_csv` method in Pandas loads all rows of the dataset into the DataFrame before filtering to remove all unwanted rows.\n",
    "\n",
    "On the other hand, the `scan_csv` method in Polars delays execution and optimizes the operation until the `collect` method is called. This approach accelerates code execution, particularly when handling large datasets.\n",
    "\n",
    "In the code below, it is 25.5 times faster to use Polars instead of Pandas to read a subset of CSV file containing 57k rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f63db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df = pd.read_csv(\"airport-codes.csv\")\n",
    "df[(df[\"type\"] == \"heliport\") & (df[\"continent\"] == \"EU\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pl.scan_csv(\"airport-codes.csv\").filter(\n",
    "    (pl.col(\"type\") == \"heliport\") & (pl.col(\"continent\") == \"EU\")\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ebc27",
   "metadata": {},
   "source": [
    "### Pandas vs Polars: Harnessing Parallelism for Faster Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5cc6e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee5233",
   "metadata": {},
   "source": [
    "Pandas is a single-threaded library, utilizing only a single CPU core. To achieve parallelism with Pandas, you would need to use additional libraries like Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"A\": range(1_000_000), \"B\": range(1_000_000)})\n",
    "\n",
    "# Perform the groupby and sum operation in parallel \n",
    "ddf = dd.from_pandas(df, npartitions=mp.cpu_count())\n",
    "result = ddf.groupby(\"A\").sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dde0a",
   "metadata": {},
   "source": [
    "Polars, on the other hand, automatically leverages the available CPU cores without any additional configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame({\"A\": range(1_000_000), \"B\": range(1_000_000)})\n",
    "\n",
    "# Perform the groupby and sum operation in parallel \n",
    "result = df.group_by(\"A\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f489f0",
   "metadata": {},
   "source": [
    "[Link to Polars](https://bit.ly/3v9dmCT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b925d9",
   "metadata": {},
   "source": [
    "### Simple and Expressive Data Transformation with Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075cc1c",
   "metadata": {},
   "source": [
    "Extract features and select only relevant features for each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a57081",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23407da3",
   "metadata": {},
   "source": [
    "Compared to pandas, Polars provides a more expressive syntax for creating complex data transformation pipelines. Every expression in Polars produces a new expression, and these expressions can be piped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71440db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"A\": [1, 2, 6], \"B\": [\"a\", \"b\", \"c\"], \"C\": [True, False, True]}\n",
    ")\n",
    "integer_columns = df.select_dtypes(\"int64\")\n",
    "other_columns = df[[\"B\"]]\n",
    "pd.concat([integer_columns, other_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e011ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl_df = pl.DataFrame(\n",
    "    {\"A\": [1, 2, 6], \"B\": [\"a\", \"b\", \"c\"], \"C\": [True, False, True]}\n",
    ")\n",
    "pl_df.select([pl.col(pl.Int64), \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec2d5c",
   "metadata": {},
   "source": [
    "### Harness Polars and Delta Lake for Blazing Fast Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4300fa1",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars deltalake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121c6a0",
   "metadata": {},
   "source": [
    "Polars is a Rust-based DataFrame library that is designed for high-performance data manipulation and analysis. Delta Lake is a storage format that offers a range of benefits, including ACID transactions, time travel, schema enforcement, and more. It's designed to work seamlessly with big data processing engines like Apache Spark and can handle large amounts of data with ease.\n",
    "\n",
    "\n",
    "When you combine Polars and Delta Lake, you get a powerful data processing system. Polars does the heavy lifting of processing your data, while Delta Lake keeps everything organized and up-to-date.\n",
    "\n",
    "Imagine you have a huge dataset with millions of rows. You want to group the data by category and calculate the sum of a certain column. With Polars and Delta Lake, you can do this quickly and easily.\n",
    "\n",
    "First, you create a sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7741f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "num_rows = 10_000_000\n",
    "data = {\n",
    "    \"Cat1\": np.random.choice(['A', 'B', 'C'], size=num_rows),\n",
    "    'Num1': np.random.randint(low=1, high=100, size=num_rows)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef470876",
   "metadata": {},
   "source": [
    "Next, you save the dataset to Delta Lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d44406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake.writer import write_deltalake\n",
    "\n",
    "save_path = \"tmp/data\"\n",
    "\n",
    "write_deltalake(save_path, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340b8fe",
   "metadata": {},
   "source": [
    "Then, you can use Polars to read the data from Delta Lake and perform the grouping operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "\n",
    "pl_df = pl.read_delta(save_path)\n",
    "\n",
    "print(pl_df.group_by(\"Cat1\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7ebf8",
   "metadata": {},
   "source": [
    "Let's say you want to append some new data to the existing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27521ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\"Cat1\": [\"B\", \"C\"], \"Num1\": [2, 3]})\n",
    "\n",
    "write_deltalake(save_path, new_data, mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa20d67",
   "metadata": {},
   "source": [
    "Now, you can use Polars to read the updated data from Delta Lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_pl_df = pl.read_delta(save_path)\n",
    "print(updated_pl_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0ed65",
   "metadata": {},
   "source": [
    "But what if you want to go back to the previous version of the data? With Delta Lake, you can easily do that by specifying the version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_pl_df = pl.read_delta(save_path, version=0)\n",
    "print(previous_pl_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35988da1",
   "metadata": {},
   "source": [
    "[Link to polars](https://github.com/pola-rs/polars)\n",
    "\n",
    "[Link to Delta Lake](https://github.com/delta-io/delta-rs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fea65",
   "metadata": {},
   "source": [
    "### Parallel Execution of Multiple Files with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b64b27",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647d57c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"test_data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df1 = pl.DataFrame(\n",
    "    {\"Cat\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"], \"Num\": [1, 1, 2, 2, 3, 3]}\n",
    ")\n",
    "\n",
    "df2 = pl.DataFrame(\n",
    "    {\"Cat\": [\"C\", \"B\", \"A\", \"A\", \"C\"], \"Num\": [1, 1, 2, 2, 3]}\n",
    ")\n",
    "\n",
    "df3 = pl.DataFrame(\n",
    "    {\"Cat\": [\"A\", \"C\", \"B\", \"B\"], \"Num\": [1, 1, 3, 2]}\n",
    ")\n",
    "\n",
    "# Save the dataframes as CSV files\n",
    "df1.write_csv(\"test_data/df1.csv\")\n",
    "df2.write_csv(\"test_data/df2.csv\")\n",
    "df3.write_csv(\"test_data/df3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d687f",
   "metadata": {},
   "source": [
    "If you have multiple files to process, Polars enables you to construct a query plan for each file beforehand. This allows for the efficient execution of multiple files concurrently, maximizing processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Construct a query plan for each file\n",
    "queries = []\n",
    "for file in glob.glob(\"test_data/*.csv\"):\n",
    "    q = pl.scan_csv(file).group_by(\"Cat\").agg(pl.sum(\"Num\"))\n",
    "    queries.append(q)\n",
    "\n",
    "# Execute files in parallel\n",
    "dataframes = pl.collect_all(queries)\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0516a2e",
   "metadata": {},
   "source": [
    "[Link to polars](https://github.com/pola-rs/polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb070a30",
   "metadata": {},
   "source": [
    "### Polars' Streaming Mode: A Solution for Large Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d64c7a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb7dba",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/pola-rs/polars/main/docs/data/reddit.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adba8cb",
   "metadata": {},
   "source": [
    "The default collect method in Polars processes your data as a single batch, which means that all the data must fit into your available memory.\n",
    "\n",
    "If your data requires more memory than you have available, Polars can process it in batches using streaming mode. To use streaming mode, simply pass the `streaming=True` argument to the `collect` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = (\n",
    "    pl.scan_csv(\"reddit.csv\")\n",
    "    .with_columns(pl.col(\"name\").str.to_uppercase())\n",
    "    .filter(pl.col(\"comment_karma\") > 0)\n",
    "    .collect(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b290f6",
   "metadata": {},
   "source": [
    "[Learn more about Streaming API in Polars](https://bit.ly/3wlTZXR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e1cde",
   "metadata": {},
   "source": [
    "### Pandas vs Polars: Syntax Comparison for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38da6c9",
   "metadata": {},
   "source": [
    "As a data scientist, you're likely familiar with the popular data analysis libraries Pandas and Polars. Both provide powerful tools for working with tabular data, but how do their syntaxes compare?\n",
    "\n",
    "To begin, we'll create equivalent dataframes in both Pandas and Polars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "data = {\n",
    "    \"Category\": [\"Electronics\", \"Clothing\", \"Electronics\", \"Clothing\", \"Electronics\"],\n",
    "    \"Quantity\": [5, 2, 3, 10, 4],\n",
    "    \"Price\": [200, 30, 150, 20, 300],\n",
    "}\n",
    "pandas_df = pd.DataFrame(data)\n",
    "polars_df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189c402",
   "metadata": {},
   "source": [
    "Key Operations Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[[\"Category\", \"Price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980287ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_df.select([\"Category\", \"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df618d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering rows where Quantity > 3\n",
    "pandas_df[pandas_df[\"Quantity\"] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c41eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_df.filter(pl.col(\"Quantity\") > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.groupby(\"Category\").agg(\n",
    "    {\n",
    "        \"Quantity\": \"sum\", \n",
    "        \"Price\": \"mean\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_df.group_by(\"Category\").agg(\n",
    "    [\n",
    "        pl.col(\"Quantity\").sum(),\n",
    "        pl.col(\"Price\").mean(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb20ca",
   "metadata": {},
   "source": [
    "### Faster Data Analysis with Polars: A Guide to Lazy Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215c0f8",
   "metadata": {},
   "source": [
    "When processing data, the execution approach significantly impacts performance. Pandas, a popular Python data manipulation library, uses eager execution by default, processing data immediately and loading everything into memory. This works well for small to medium-sized datasets but can lead to slow computations and high memory usage with large datasets.\n",
    "\n",
    "In contrast, Polars, a modern data processing library, offers both eager and lazy execution. In lazy mode, a query optimizer evaluates operations and determines the most efficient execution plan, which may involve reordering operations or dropping redundant calculations.\n",
    "\n",
    "Let's consider an example where we:\n",
    "\n",
    "- Group a DataFrame by 'region'\n",
    "- Calculate two aggregations: sum of 'revenue' and count of 'orders'\n",
    "- Filter for only 'North' and 'South' regions\n",
    "\n",
    "With eager execution, Pandas will:\n",
    "\n",
    "- Execute operations immediately, loading all data into memory\n",
    "- Keep intermediate results in memory during each step\n",
    "- Execute operations in the exact order written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "N = 10_000_000\n",
    "\n",
    "data = {\n",
    "    \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], N),\n",
    "    \"revenue\": np.random.uniform(100, 10000, N),\n",
    "    \"orders\": np.random.randint(1, 100, N),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analyze_sales_pandas(df):\n",
    "    # Loads and processes everything in memory\n",
    "    return (\n",
    "        df.groupby(\"region\")\n",
    "        .agg({\"revenue\": \"sum\"})\n",
    "        .loc[[\"North\", \"South\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "pd_df = pd.DataFrame(data)\n",
    "%timeit analyze_sales_pandas(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b2c38",
   "metadata": {},
   "source": [
    "As shown above, the eager execution approach used by Pandas results in a execution time of approximately 367 milliseconds.\n",
    "\n",
    "\n",
    "With lazy execution, Polars will:\n",
    "\n",
    "- Create an execution plan first, optimizing the entire chain before processing any data\n",
    "- Only process data once at .collect(), reducing memory overhead\n",
    "- Rearrange operations for optimal performance (pushing filters before groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "def analyze_sales_polars(df):\n",
    "    # Creates execution plan, no data processed yet\n",
    "    result = (\n",
    "        df.lazy()\n",
    "        .group_by(\"region\")\n",
    "        .agg(pl.col(\"revenue\").sum())\n",
    "        .filter(pl.col(\"region\").is_in([\"North\", \"South\"]))\n",
    "        .collect()  # Only now data is processed\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "pl_df = pl.DataFrame(data)\n",
    "%timeit analyze_sales_polars(pl_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab662580",
   "metadata": {},
   "source": [
    "In contrast, the lazy execution approach with Polars takes approximately 170 milliseconds to complete, which is about 53.68% faster than the eager execution approach with Pandas."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.7"
   }
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   20,
   24,
   30,
   64,
   66,
   70,
   74,
   78,
   90,
   111,
   115,
   123,
   125,
   129,
   135,
   137,
   141,
   145,
   151,
   155,
   163,
   168,
   174,
   179,
   183,
   187,
   191,
   202,
   206,
   213,
   217,
   221,
   225,
   229,
   233,
   244,
   251,
   255,
   259,
   270,
   283,
   287,
   293,
   297,
   303,
   307,
   311,
   315,
   318,
   322,
   325,
   331,
   335,
   341,
   365,
   369,
   383,
   387,
   391,
   397,
   401,
   407,
   416,
   420,
   424,
   430,
   442,
   446,
   450,
   454,
   459,
   463,
   472,
   479,
   483,
   501,
   514,
   529,
   540,
   558
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}