{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbc22c85",
   "metadata": {},
   "source": [
    "## Manage Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53e056d",
   "metadata": {},
   "source": [
    "This section covers some tools to work with your data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9051997b",
   "metadata": {},
   "source": [
    "### DVC: A Data Version Control Tool for Your Data Science Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf178f7c",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install dvc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b08836d",
   "metadata": {},
   "source": [
    "While Git excels at versioning code, managing data versions can be tricky. DVC (Data Version Control) bridges this gap by allowing you to track data changes alongside your code, while keeping the actual data separate. It's like Git for data.\n",
    "\n",
    "Here’s a quick start guide for DVC:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfb6b5cf",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Initialize\n",
    "$ dvc init\n",
    "\n",
    "# Track data directory\n",
    "$ dvc add data # Create data.dvc\n",
    "$ git add data.dvc\n",
    "$ git commit -m \"add data\"\n",
    "\n",
    "# Store the data remotely\n",
    "$ dvc remote add -d remote gdrive://lynNBbT-4J0ida0eKYQqZZbC93juUUUbVH\n",
    "\n",
    "# Push the data to remote storage\n",
    "$ dvc push \n",
    "\n",
    "# Get the data\n",
    "$ dvc pull \n",
    "\n",
    "# Switch between different version\n",
    "$ git checkout HEAD^1 data.dvc\n",
    "$ dvc checkout\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84ead3ce",
   "metadata": {},
   "source": [
    "[Link to DVC](https://dvc.org/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b0a3099",
   "metadata": {},
   "source": [
    "### sweetviz: Compare the similar features between 2 different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f728a43",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sweetviz "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c23e08",
   "metadata": {},
   "source": [
    "When comparing datasets, such as training and testing sets, sweetviz helps visualize similarities and differences with ease.\n",
    "\n",
    "Here’s how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6e248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-11T19:08:20.830420Z",
     "start_time": "2021-09-11T19:08:18.515134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sweetviz as sv\n",
    "\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "report = sv.compare([X_train, \"train data\"], [X_test, \"test data\"])\n",
    "report.show_html()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55c80d06",
   "metadata": {},
   "source": [
    "![image](../img/sweetviz_output.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71e6fe87",
   "metadata": {},
   "source": [
    "[Link to sweetviz](https://github.com/fbdesignpro/sweetviz)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eea1ba01",
   "metadata": {},
   "source": [
    "### quadratic: Data Science Speadsheet with Python and SQL\n",
    "\n",
    "If you want to use Python or SQL in an Excel sheet, use quadratic.\n",
    "\n",
    "![](../img/quadratic.gif)\n",
    "\n",
    "[Link to quadratic](https://github.com/quadratichq/quadratic).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce67f3bf",
   "metadata": {},
   "source": [
    "### whylogs: Data Logging Made Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8637b8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install whylogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c6852f9",
   "metadata": {},
   "source": [
    "Keeping track of dataset statistics is crucial for data quality and monitoring. whylogs makes logging dataset summaries straightforward.\n",
    "\n",
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cd22db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality/est</th>\n",
       "      <th>cardinality/lower_1</th>\n",
       "      <th>cardinality/upper_1</th>\n",
       "      <th>counts/inf</th>\n",
       "      <th>counts/n</th>\n",
       "      <th>counts/nan</th>\n",
       "      <th>counts/null</th>\n",
       "      <th>distribution/max</th>\n",
       "      <th>distribution/mean</th>\n",
       "      <th>distribution/median</th>\n",
       "      <th>...</th>\n",
       "      <th>frequent_items/frequent_strings</th>\n",
       "      <th>type</th>\n",
       "      <th>types/boolean</th>\n",
       "      <th>types/fractional</th>\n",
       "      <th>types/integral</th>\n",
       "      <th>types/object</th>\n",
       "      <th>types/string</th>\n",
       "      <th>types/tensor</th>\n",
       "      <th>ints/max</th>\n",
       "      <th>ints/min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Color</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='Yellow', est=1, upper=1, ...</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruit</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='Orange', est=1, upper=1, ...</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='8', est=1, upper=1, lower...</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cardinality/est  cardinality/lower_1  cardinality/upper_1  \\\n",
       "column                                                                \n",
       "Color                 3.0                  3.0              3.00015   \n",
       "Fruit                 3.0                  3.0              3.00015   \n",
       "Quantity              3.0                  3.0              3.00015   \n",
       "\n",
       "          counts/inf  counts/n  counts/nan  counts/null  distribution/max  \\\n",
       "column                                                                      \n",
       "Color              0         3           0            0               NaN   \n",
       "Fruit              0         3           0            0               NaN   \n",
       "Quantity           0         3           0            0               8.0   \n",
       "\n",
       "          distribution/mean  distribution/median  ...  \\\n",
       "column                                            ...   \n",
       "Color              0.000000                  NaN  ...   \n",
       "Fruit              0.000000                  NaN  ...   \n",
       "Quantity           5.333333                  5.0  ...   \n",
       "\n",
       "                            frequent_items/frequent_strings  \\\n",
       "column                                                        \n",
       "Color     [FrequentItem(value='Yellow', est=1, upper=1, ...   \n",
       "Fruit     [FrequentItem(value='Orange', est=1, upper=1, ...   \n",
       "Quantity  [FrequentItem(value='8', est=1, upper=1, lower...   \n",
       "\n",
       "                        type  types/boolean  types/fractional  types/integral  \\\n",
       "column                                                                          \n",
       "Color     SummaryType.COLUMN              0                 0               0   \n",
       "Fruit     SummaryType.COLUMN              0                 0               0   \n",
       "Quantity  SummaryType.COLUMN              0                 0               3   \n",
       "\n",
       "          types/object  types/string  types/tensor  ints/max  ints/min  \n",
       "column                                                                  \n",
       "Color                0             3             0       NaN       NaN  \n",
       "Fruit                0             3             0       NaN       NaN  \n",
       "Quantity             0             0             0       8.0       3.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import whylogs as why\n",
    "\n",
    "data = {\n",
    "    \"Fruit\": [\"Apple\", \"Banana\", \"Orange\"],\n",
    "    \"Color\": [\"Red\", \"Yellow\", \"Orange\",],\n",
    "    \"Quantity\": [5, 8, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Log the DataFrame using whylogs and create a profile\n",
    "profile = why.log(df).profile()\n",
    "\n",
    "# View the profile and convert it to a pandas DataFrame\n",
    "prof_view = profile.view()\n",
    "prof_df = prof_view.to_pandas()\n",
    "prof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc36efc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality/est</th>\n",
       "      <th>cardinality/lower_1</th>\n",
       "      <th>cardinality/upper_1</th>\n",
       "      <th>counts/inf</th>\n",
       "      <th>counts/n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Color</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruit</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cardinality/est  cardinality/lower_1  cardinality/upper_1  \\\n",
       "column                                                                \n",
       "Color                 3.0                  3.0              3.00015   \n",
       "Fruit                 3.0                  3.0              3.00015   \n",
       "Quantity              3.0                  3.0              3.00015   \n",
       "\n",
       "          counts/inf  counts/n  \n",
       "column                          \n",
       "Color              0         3  \n",
       "Fruit              0         3  \n",
       "Quantity           0         3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e215f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cardinality/est', 'cardinality/lower_1', 'cardinality/upper_1',\n",
       "       'counts/inf', 'counts/n', 'counts/nan', 'counts/null',\n",
       "       'distribution/max', 'distribution/mean', 'distribution/median',\n",
       "       'distribution/min', 'distribution/n', 'distribution/q_01',\n",
       "       'distribution/q_05', 'distribution/q_10', 'distribution/q_25',\n",
       "       'distribution/q_75', 'distribution/q_90', 'distribution/q_95',\n",
       "       'distribution/q_99', 'distribution/stddev',\n",
       "       'frequent_items/frequent_strings', 'type', 'types/boolean',\n",
       "       'types/fractional', 'types/integral', 'types/object', 'types/string',\n",
       "       'types/tensor', 'ints/max', 'ints/min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01ca1052",
   "metadata": {},
   "source": [
    "[Link to whylogs](https://github.com/whylabs/whylogs)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13ee4558",
   "metadata": {},
   "source": [
    "### Fluke: The Easiest Way to Move Data Around"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fd676d8",
   "metadata": {},
   "source": [
    "Transferring data between locations—such as from a remote server to cloud storage—can be cumbersome, especially with Python libraries that involve complex HTTP/SSH connections and directory handling. \n",
    "\n",
    "Fluke simplifies this process with a user-friendly API, making it easy to manage remote data transfers with just a few lines of code.\n",
    "\n",
    "Example usage:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b436d6e",
   "metadata": {},
   "source": [
    "```python\n",
    "from fluke.auth import RemoteAuth, AWSAuth\n",
    "\n",
    "# This object will be used to authenticate\n",
    "# with the remote machine.\n",
    "rmt_auth = RemoteAuth.from_password(\n",
    "    hostname=\"host\",\n",
    "    username=\"user\",\n",
    "    password=\"password\")\n",
    "\n",
    "# This object will be used to authenticate\n",
    "# with AWS.\n",
    "aws_auth = AWSAuth(\n",
    "    aws_access_key_id=\"aws_access_key\",\n",
    "    aws_secret_access_key=\"aws_secret_key\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40a1d234",
   "metadata": {},
   "source": [
    "```python\n",
    "from fluke.storage import RemoteDir, AWSS3Dir\n",
    "\n",
    "with (\n",
    "    RemoteDir(auth=rmt_auth, path='/home/user/dir') as rmt_dir,\n",
    "    AWSS3Dir(auth=aws_auth, bucket=\"bucket\", path='dir', create_if_missing=True) as aws_dir\n",
    "):\n",
    "    rmt_dir.transfer_to(dst=aws_dir, recursively=True)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e96430a1",
   "metadata": {},
   "source": [
    "[Link to Fluke](https://github.com/manoss96/fluke)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dff10a",
   "metadata": {},
   "source": [
    "### safetensors: A Simple and Safe Way to Store and Distribute Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25910bc",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install torch safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec934b",
   "metadata": {},
   "source": [
    "PyTorch defaults to using Pickle for tensor storage, which poses security risks as malicious pickle files can execute arbitrary code upon unpickling. In contrast, safetensors specialize in securely storing tensors, guaranteeing data integrity during storage and retrieval. \n",
    "\n",
    "safetensors also uses zero-copy operations, eliminating the need to copy data into new memory locations, thereby enabling fast and efficient data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb5d46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "tensors = {\n",
    "   \"weight1\": torch.zeros((1024, 1024)),\n",
    "   \"weight2\": torch.zeros((1024, 1024))\n",
    "}\n",
    "save_file(tensors, \"model.safetensors\")\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\"model.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "   for key in f.keys():\n",
    "       tensors[key] = f.get_tensor(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9981d0",
   "metadata": {},
   "source": [
    "[Link to safetensors](https://bit.ly/3vqzbhl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c033d-6909-4f29-b2f9-7d73b385f118",
   "metadata": {},
   "source": [
    "### datacompy: Smart Data Comparison Made Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb43688-b0c9-4b04-8b7b-52921ddf5d03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install datacompy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b82f2b-b7cd-4fde-9702-dbcdbb4157a9",
   "metadata": {},
   "source": [
    "Data analysts and data engineers often struggle with comparing two datasets. This results in writing complex code to compare values, identify mismatches, and generate comparison reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc7d348-aac2-4556-b62e-a25461c943b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct_id</th>\n",
       "      <th>dollar_amt</th>\n",
       "      <th>name</th>\n",
       "      <th>float_fld</th>\n",
       "      <th>date_fld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001234</td>\n",
       "      <td>123.45</td>\n",
       "      <td>George Maharis</td>\n",
       "      <td>14530.1555</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001235</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Michael Bluth</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000001236</td>\n",
       "      <td>1345.00</td>\n",
       "      <td>George Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000001237</td>\n",
       "      <td>123456.00</td>\n",
       "      <td>Bob Loblaw</td>\n",
       "      <td>345.1200</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Lucille Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Loose Seal Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acct_id  dollar_amt              name   float_fld    date_fld\n",
       "0  10000001234      123.45    George Maharis  14530.1555  2017-01-01\n",
       "1  10000001235        0.45     Michael Bluth      1.0000  2017-01-01\n",
       "2  10000001236     1345.00      George Bluth         NaN  2017-01-01\n",
       "3  10000001237   123456.00        Bob Loblaw    345.1200  2017-01-01\n",
       "4  10000001238        1.05     Lucille Bluth         NaN  2017-01-01\n",
       "5  10000001238        1.05  Loose Seal Bluth         NaN  2017-01-01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "data1 = \"\"\"acct_id,dollar_amt,name,float_fld,date_fld\n",
    "10000001234,123.45,George Maharis,14530.1555,2017-01-01\n",
    "10000001235,0.45,Michael Bluth,1,2017-01-01\n",
    "10000001236,1345,George Bluth,,2017-01-01\n",
    "10000001237,123456,Bob Loblaw,345.12,2017-01-01\n",
    "10000001238,1.05,Lucille Bluth,,2017-01-01\n",
    "10000001238,1.05,Loose Seal Bluth,,2017-01-01\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_csv(StringIO(data1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b57183-02d5-413e-9a72-9143c2176c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct_id</th>\n",
       "      <th>dollar_amt</th>\n",
       "      <th>name</th>\n",
       "      <th>float_fld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001234</td>\n",
       "      <td>123.40</td>\n",
       "      <td>George Michael Bluth</td>\n",
       "      <td>14530.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001235</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Michael Bluth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000001236</td>\n",
       "      <td>1345.00</td>\n",
       "      <td>George Bluth</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000001237</td>\n",
       "      <td>123456.00</td>\n",
       "      <td>Robert Loblaw</td>\n",
       "      <td>345.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Loose Seal Bluth</td>\n",
       "      <td>111.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acct_id  dollar_amt                  name  float_fld\n",
       "0  10000001234      123.40  George Michael Bluth  14530.155\n",
       "1  10000001235        0.45         Michael Bluth        NaN\n",
       "2  10000001236     1345.00          George Bluth      1.000\n",
       "3  10000001237   123456.00         Robert Loblaw    345.120\n",
       "4  10000001238        1.05      Loose Seal Bluth    111.000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = \"\"\"acct_id,dollar_amt,name,float_fld\n",
    "10000001234,123.4,George Michael Bluth,14530.155\n",
    "10000001235,0.45,Michael Bluth,\n",
    "10000001236,1345,George Bluth,1\n",
    "10000001237,123456,Robert Loblaw,345.12\n",
    "10000001238,1.05,Loose Seal Bluth,111\n",
    "\"\"\"\n",
    "\n",
    "df2 = pd.read_csv(StringIO(data2))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49f1039-0ab7-4589-94e9-8fc7f0c8c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes match: False\n",
      "\n",
      "Mismatches:\n",
      "       acct_id  dollar_amt_1                  name  float_fld_1    date_fld  \\\n",
      "0  10000001234        123.45        George Maharis   14530.1555  2017-01-01   \n",
      "3  10000001237     123456.00            Bob Loblaw     345.1200  2017-01-01   \n",
      "4  10000001238          1.05         Lucille Bluth          NaN  2017-01-01   \n",
      "6  10000001234           NaN  George Michael Bluth          NaN         NaN   \n",
      "7  10000001237           NaN         Robert Loblaw          NaN         NaN   \n",
      "\n",
      "   dollar_amt_2  float_fld_2  \n",
      "0           NaN          NaN  \n",
      "3           NaN          NaN  \n",
      "4           NaN          NaN  \n",
      "6         123.4    14530.155  \n",
      "7      123456.0      345.120  \n",
      "\n",
      "Missing records:\n",
      "       acct_id  dollar_amt_1                  name  float_fld_1    date_fld  \\\n",
      "0  10000001234        123.45        George Maharis   14530.1555  2017-01-01   \n",
      "3  10000001237     123456.00            Bob Loblaw     345.1200  2017-01-01   \n",
      "4  10000001238          1.05         Lucille Bluth          NaN  2017-01-01   \n",
      "6  10000001234           NaN  George Michael Bluth          NaN         NaN   \n",
      "7  10000001237           NaN         Robert Loblaw          NaN         NaN   \n",
      "\n",
      "   dollar_amt_2  float_fld_2  \n",
      "0           NaN          NaN  \n",
      "3           NaN          NaN  \n",
      "4           NaN          NaN  \n",
      "6         123.4    14530.155  \n",
      "7      123456.0      345.120  \n"
     ]
    }
   ],
   "source": [
    "# Check if shapes match\n",
    "shape_match = df1.shape == df2.shape\n",
    "\n",
    "# Compare values\n",
    "merged = df1.merge(df2, on=['acct_id', 'name'], how='outer', suffixes=('_1', '_2'))\n",
    "mismatches = merged[merged['dollar_amt_1'] != merged['dollar_amt_2']]\n",
    "missing = merged[merged['dollar_amt_1'].isna() | merged['dollar_amt_2'].isna()]\n",
    "\n",
    "# Manual reporting\n",
    "print(f\"Shapes match: {shape_match}\")\n",
    "print(\"\\nMismatches:\")\n",
    "print(mismatches)\n",
    "print(\"\\nMissing records:\")\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1885ca6-9dfb-4cd1-ae0e-88fc7c544c37",
   "metadata": {},
   "source": [
    "With datacompy, you can easily compare datasets and get detailed reports about differences, including matching percentage, column-level comparison, and sample mismatches. You can use it with various data frameworks like Pandas, Spark, Polars, and Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ac4579-a03d-4e82-8d93-bbccf1fc4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacompy\n",
    "\n",
    "compare = datacompy.Compare(df1, df2, join_columns=['acct_id', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8b16b73-7139-4284-ac80-bfb14c37d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "  DataFrame  Columns  Rows\n",
      "0       df1        5     6\n",
      "1       df2        4     5\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 4\n",
      "Number of columns in df1 but not in df2: 1 ['date_fld']\n",
      "Number of columns in df2 but not in df1: 0 []\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: acct_id, name\n",
      "Any duplicates on match values: No\n",
      "Absolute Tolerance: 0\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 3\n",
      "Number of rows in df1 but not in df2: 3\n",
      "Number of rows in df2 but not in df1: 2\n",
      "\n",
      "Number of rows with some compared columns unequal: 3\n",
      "Number of rows with all compared columns equal: 0\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 1\n",
      "Number of columns compared with all values equal: 3\n",
      "Total number of values which compare unequal: 3\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "      Column df1 dtype df2 dtype  # Unequal  Max Diff  # Null Diff\n",
      "0  float_fld   float64   float64          3       NaN            3\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "       acct_id              name  float_fld (df1)  float_fld (df2)\n",
      "0  10000001236      George Bluth              NaN              1.0\n",
      "1  10000001238  Loose Seal Bluth              NaN            111.0\n",
      "2  10000001235     Michael Bluth              1.0              NaN\n",
      "\n",
      "Sample Rows Only in df1 (First 10 Columns)\n",
      "------------------------------------------\n",
      "\n",
      "       acct_id  dollar_amt            name   float_fld    date_fld\n",
      "0  10000001238        1.05   Lucille Bluth         NaN  2017-01-01\n",
      "1  10000001234      123.45  George Maharis  14530.1555  2017-01-01\n",
      "2  10000001237   123456.00      Bob Loblaw    345.1200  2017-01-01\n",
      "\n",
      "Sample Rows Only in df2 (First 10 Columns)\n",
      "------------------------------------------\n",
      "\n",
      "       acct_id  dollar_amt                  name  float_fld\n",
      "0  10000001237    123456.0         Robert Loblaw    345.120\n",
      "1  10000001234       123.4  George Michael Bluth  14530.155\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compare.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0d8cf-3744-410a-ab8f-04c6ad4a3262",
   "metadata": {},
   "source": [
    "[Link to datacompy](https://github.com/capitalone/datacompy)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
