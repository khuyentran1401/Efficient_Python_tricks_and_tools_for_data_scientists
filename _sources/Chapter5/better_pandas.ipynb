{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8aae599",
   "metadata": {},
   "source": [
    "## Better Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eecde9",
   "metadata": {},
   "source": [
    "This section cover tools to make your experience with Pandas a litte bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6b55b",
   "metadata": {},
   "source": [
    "### tqdm: Add Progress Bar to Your Pandas Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e26f06",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea96f0",
   "metadata": {},
   "source": [
    "If you want to keep informed about the progress of a pandas apply operation, use tqdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import time \n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3, 4, 5], 'b': [2, 3, 4, 5, 6]})\n",
    "\n",
    "tqdm.pandas()\n",
    "def func(row):\n",
    "    time.sleep(1)\n",
    "    return row + 1\n",
    "\n",
    "df['a'].progress_apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc938e",
   "metadata": {},
   "source": [
    "[Link to tqdm](https://github.com/tqdm/tqdm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bcb43",
   "metadata": {},
   "source": [
    "### pandarallel: A Simple Tool to Parallelize Pandas Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c850b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87cfe0",
   "metadata": {},
   "source": [
    "If you want to parallelize your Pandas operations on all available CPUs by adding only one line of code, try pandarallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14633518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": randint(0, 100, size=10000),\n",
    "        \"b\": randint(0, 100, size=10000),\n",
    "        \"c\": randint(0, 100, size=10000),\n",
    "    }\n",
    ")\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "df.parallel_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa83149",
   "metadata": {},
   "source": [
    "[Link to pandarallel](https://github.com/nalepae/pandarallel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffd208",
   "metadata": {},
   "source": [
    "### PandasAI: Gain Insights From Your pandas DataFrame With AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70300759",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pandasai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d3150",
   "metadata": {},
   "source": [
    "If you want to quickly gain insights from your pandas DataFrame with AI, use PandasAI. PandasAI serves as: \n",
    "\n",
    "- A tool to analyze your DataFrame\n",
    "- Not a tool to process your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76136f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/flights.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aeba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI\n",
    "\n",
    "# Instantiate a LLM\n",
    "llm = OpenAI(api_token=\"YOUR_API_TOKEN\")\n",
    "\n",
    "# Use pandasai\n",
    "pandas_ai = PandasAI(llm, conversational=False)\n",
    "print(\n",
    "    pandas_ai.run(\n",
    "        df,\n",
    "        prompt=\"Which month of the years has the highest number of passengers on average?\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pandas_ai.run(\n",
    "        df, prompt=\"Which are the five years with the highest passenger numbers?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pandas_ai.run(df, prompt=\"Within what range of years does the dataset span?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ebc31",
   "metadata": {},
   "source": [
    "[Link to PandasAI](https://github.com/gventuri/pandas-ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4338da9",
   "metadata": {},
   "source": [
    "### fugue: Use pandas Functions on the Spark and Dask Engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ecd54",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install fugue pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a48b75",
   "metadata": {},
   "source": [
    "Wouldn't it be nice if you can leverage Spark or Dask to parallelize data science workloads using pandas syntax? Fugue allows you to do exactly that.\n",
    "\n",
    "Fugue provides the `transform` function allowing users to use pandas functions on the Spark and Dask engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2682f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from fugue import transform\n",
    "from fugue_spark import SparkExecutionEngine\n",
    "\n",
    "input_df = pd.DataFrame({\"id\": [0, 1, 2], \"fruit\": ([\"apple\", \"banana\", \"orange\"])})\n",
    "map_price = {\"apple\": 2, \"banana\": 1, \"orange\": 3}\n",
    "\n",
    "\n",
    "def map_price_to_fruit(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    df[\"price\"] = df[\"fruit\"].map(mapping)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = transform(\n",
    "    input_df,\n",
    "    map_price_to_fruit,\n",
    "    schema=\"*, price:int\",\n",
    "    params=dict(mapping=map_price),\n",
    "    engine=SparkExecutionEngine,\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a486a",
   "metadata": {},
   "source": [
    "[Link to fugue](https://github.com/fugue-project/fugue)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d269a3",
   "metadata": {},
   "source": [
    "### Simplifying Geographic Calculations with GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2827b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d33d0f",
   "metadata": {},
   "source": [
    "Working with geographic data in Python without proper tools can be complex and cumbersome. \n",
    "\n",
    "Example of working with geographic data without specialized tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually handling coordinates and spatial operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Complex manual handling of polygon coordinates\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Area1', 'Area2'],\n",
    "    'coordinates': [\n",
    "        [(0, 0), (1, 0), (1, 1)],\n",
    "        [(2, 0), (3, 0), (3, 1), (2, 1)]\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Calculate area\n",
    "def calculate_polygon_area(coordinates):\n",
    "    x_coords = [point[0] for point in coordinates]\n",
    "    y_coords = [point[1] for point in coordinates]\n",
    "    \n",
    "    # Add first point to end to close the polygon\n",
    "    x_shifted = x_coords[1:] + x_coords[:1] \n",
    "    y_shifted = y_coords[1:] + y_coords[:1]\n",
    "    \n",
    "    # Calculate using shoelace formula\n",
    "    first_sum = sum(x * y for x, y in zip(x_coords, y_shifted))\n",
    "    second_sum = sum(x * y for x, y in zip(x_shifted, y_coords))\n",
    "    area = 0.5 * abs(first_sum - second_sum)\n",
    "    \n",
    "    return area\n",
    "\n",
    "df['area'] = df['coordinates'].apply(calculate_polygon_area)\n",
    "df['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parameter\n",
    "def calculate_perimeter(coordinates):\n",
    "    # Add first point to end to close the polygon if not already closed\n",
    "    if coordinates[0] != coordinates[-1]:\n",
    "        coordinates = coordinates + [coordinates[0]]\n",
    "    \n",
    "    # Calculate distance between consecutive points\n",
    "    distances = []\n",
    "    for i in range(len(coordinates)-1):\n",
    "        point1 = coordinates[i]\n",
    "        point2 = coordinates[i+1]\n",
    "        # Euclidean distance formula\n",
    "        distance = np.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    return sum(distances)\n",
    "\n",
    "df['perimeter'] = df['coordinates'].apply(calculate_perimeter)\n",
    "df['perimeter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a577a4c",
   "metadata": {},
   "source": [
    "With GeoPandas, you can:\n",
    "\n",
    "- Work with geometric objects (points, lines, polygons) directly in DataFrame-like structures\n",
    "- Perform spatial operations (intersections, unions, buffers) easily\n",
    "- Visualize geographic data with simple plotting commands\n",
    "\n",
    "Example using GeoPandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320764ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Create two polygons\n",
    "p1 = Polygon([(0, 0), (1, 0), (1, 1)])\n",
    "p2 = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n",
    "    \n",
    "# Create a GeoSeries from the polygons\n",
    "g = geopandas.GeoSeries([p1, p2])\n",
    "    \n",
    "# Print the GeoSeries\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf64cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area\n",
    "g.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perimater of each polygon\n",
    "g.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d273ebc",
   "metadata": {},
   "source": [
    "[Link to GeoPandas](https://github.com/geopandas/geopandas)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   20,
   24,
   28,
   32,
   45,
   49,
   53,
   57,
   61,
   76,
   80,
   84,
   88,
   95,
   102,
   106,
   123,
   131,
   133,
   137,
   141,
   145,
   151,
   174,
   178,
   182,
   190,
   196,
   230,
   250,
   260,
   275,
   280,
   285,
   290
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}