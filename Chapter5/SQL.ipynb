{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf9d9ab-cf44-4dfb-8d4c-e1b2c4f2a00b",
   "metadata": {},
   "source": [
    "# SQL Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794a12e-cef2-4aa3-bc66-647400e426de",
   "metadata": {},
   "source": [
    "## Create Dynamic SQL Statements with Python string Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4213f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing query.sql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.sql\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    my_table\n",
    "LIMIT\n",
    "    $limit\n",
    "WHERE\n",
    "    start_date > $start_date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f445bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    *\n",
      "FROM\n",
      "    my_table\n",
      "LIMIT\n",
      "    10\n",
      "WHERE\n",
      "    start_date > 2021-01-01;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from string import Template\n",
    "\n",
    "## Read the query from the file\n",
    "query = pathlib.Path(\"query.sql\").read_text()\n",
    "\n",
    "## Substitute the placeholders with the values\n",
    "t = Template(query)\n",
    "substitutions = {\"limit\": 10, \"start_date\": \"2021-01-01\"}\n",
    "print(t.substitute(substitutions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7832641b",
   "metadata": {},
   "source": [
    "Loading SQL tables into DataFrames allows you to analyze and preprocess the data using the rich functionality of pandas.\n",
    "\n",
    "To read a SQL table into a pandas DataFrame, pass the database connection obtained from the SQLAlchemy Engine to the `pandas.read_sql` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d09ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql://username:password@host:port/database_name\"\n",
    ")\n",
    "\n",
    "\n",
    "## Read a SQL table into a DataFrame\n",
    "df = pd.read_sql(\"SELECT * FROM table_name\", engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a14c44c",
   "metadata": {},
   "source": [
    "## FugueSQL: Use SQL to Work with Pandas, Spark, and Dask DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fe777",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install fugue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e7c873c",
   "metadata": {},
   "source": [
    "Do you like to use both Python and SQL to manipulate data? FugueSQL is an interface that allows users to use SQL to work with Pandas, Spark, and Dask DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "price:long|fruit:str\n",
      "----------+---------\n",
      "2         |apple    \n",
      "3         |orange   \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fugue_sql import fsql\n",
    "\n",
    "input_df = pd.DataFrame({\"price\": [2, 1, 3], \"fruit\": ([\"apple\", \"banana\", \"orange\"])})\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT price, fruit FROM input_df\n",
    "WHERE price > 1\n",
    "PRINT\n",
    "\"\"\"\n",
    "\n",
    "fsql(query).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93163c1a",
   "metadata": {},
   "source": [
    "[Link to fugue](https://github.com/fugue-project/fugue).\n",
    "\n",
    "## SQLModel: Simplify SQL Database Interactions in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb088e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sqlmodel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1d64645",
   "metadata": {},
   "source": [
    "Interacting with SQL databases from Python code can often be challenging to write and comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "## Connect to the database\n",
    "conn = sqlite3.connect(\"users.db\")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "## Define the SQL statement for creating the table\n",
    "create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS membership (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        username TEXT,\n",
    "        age INTEGER,\n",
    "        active INTEGER\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "## Execute the SQL statement to create the table\n",
    "cursor.execute(create_table_sql)\n",
    "\n",
    "## Define the SQL statement for inserting rows\n",
    "insert_rows_sql = \"\"\"\n",
    "    INSERT INTO membership (username, age, active)\n",
    "    VALUES (?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "## Define the rows to be inserted\n",
    "rows = [(\"John\", 25, 1), (\"Jane\", 30, 0), (\"Mike\", 35, 1)]\n",
    "\n",
    "## Execute the SQL statement for each row\n",
    "for row in rows:\n",
    "    cursor.execute(insert_rows_sql, row)\n",
    "\n",
    "## Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "## Close the cursor and the database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd5364a6",
   "metadata": {},
   "source": [
    "However, by utilizing SQLModel, you can harness Pydantic-like classes that leverage Python type annotations, making the code more intuitive to write and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from sqlmodel import Field, Session, SQLModel, create_engine\n",
    "\n",
    "\n",
    "class Membership(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    username: str\n",
    "    age: int\n",
    "    active: int\n",
    "\n",
    "\n",
    "# age is converted from str to int through type coercion\n",
    "user1 = Membership(username=\"John\", age=\"25\", active=1)\n",
    "user2 = Membership(username=\"Jane\", age=\"30\", active=0)\n",
    "user3 = Membership(username=\"Mike\", age=\"35\", active=1)\n",
    "\n",
    "\n",
    "engine = create_engine(\"sqlite:///users.db\")\n",
    "\n",
    "\n",
    "SQLModel.metadata.create_all(engine)\n",
    "\n",
    "with Session(engine) as session:\n",
    "    session.add(user1)\n",
    "    session.add(user2)\n",
    "    session.add(user3)\n",
    "    session.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54e86d04",
   "metadata": {},
   "source": [
    "[Link to SQLModel](https://github.com/tiangolo/sqlmodel).\n",
    "\n",
    "## SQLFluff: A Linter and Auto-Formatter for Your SQL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad118bdb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sqlfluff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c9bed-740f-451e-8b9e-9a66c646f748",
   "metadata": {},
   "source": [
    "Inconsistent SQL formatting and style errors can reduce code readability and make code reviews more difficult.\n",
    "\n",
    "SQLFluff solves this problem by automatically linting and fixing SQL code formatting issues across multiple dialects, including ANSI, MySQL, PostgreSQL, BigQuery, Databricks, Oracle, and more.\n",
    "\n",
    "To demonstrate, let's create a sample SQL file named `sqlfluff_example.sql` with a simple `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sqlfluff_example.sql\n",
    "SELECT a+b  AS foo,\n",
    "c AS bar from my_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f66b3c",
   "metadata": {},
   "source": [
    "Next, run the SQLFluff linter on the `sqlfluff_example.sql` file using the PostgreSQL dialect. \n",
    "\n",
    "```bash\n",
    "$ sqlfluff lint sqlfluff_example.sql --dialect postgres\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3b30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== [\u001b[30m\u001b[1msqlfluff_example.sql\u001b[0m] \u001b[31mFAIL\u001b[0m                            \n",
      "\u001b[34mL:   1 | P:   1 | LT09 | \u001b[0mSelect targets should be on a new line unless there is\n",
      "                       \u001b[34m| \u001b[0monly one select target.\n",
      "                       \u001b[34m| \u001b[0m[\u001b[30m\u001b[1mlayout.select_targets\u001b[0m]\n",
      "\u001b[34mL:   1 | P:   1 | ST06 | \u001b[0mSelect wildcards then simple targets before calculations\n",
      "                       \u001b[34m| \u001b[0mand aggregates. [\u001b[30m\u001b[1mstructure.column_order\u001b[0m]\n",
      "\u001b[34mL:   1 | P:   7 | LT02 | \u001b[0mExpected line break and indent of 4 spaces before 'a'.\n",
      "                       \u001b[34m| \u001b[0m[\u001b[30m\u001b[1mlayout.indent\u001b[0m]\n",
      "\u001b[34mL:   1 | P:   9 | LT01 | \u001b[0mExpected single whitespace between naked identifier and\n",
      "                       \u001b[34m| \u001b[0mbinary operator '+'. [\u001b[30m\u001b[1mlayout.spacing\u001b[0m]\n",
      "\u001b[34mL:   1 | P:  10 | LT01 | \u001b[0mExpected single whitespace between binary operator '+'\n",
      "                       \u001b[34m| \u001b[0mand naked identifier. [\u001b[30m\u001b[1mlayout.spacing\u001b[0m]\n",
      "\u001b[34mL:   1 | P:  11 | LT01 | \u001b[0mExpected only single space before 'AS' keyword. Found ' \n",
      "                       \u001b[34m| \u001b[0m'. [\u001b[30m\u001b[1mlayout.spacing\u001b[0m]\n",
      "\u001b[34mL:   2 | P:   1 | LT02 | \u001b[0mExpected indent of 4 spaces.\n",
      "                       \u001b[34m| \u001b[0m[\u001b[30m\u001b[1mlayout.indent\u001b[0m]\n",
      "\u001b[34mL:   2 | P:   9 | LT02 | \u001b[0mExpected line break and no indent before 'from'.\n",
      "                       \u001b[34m| \u001b[0m[\u001b[30m\u001b[1mlayout.indent\u001b[0m]\n",
      "\u001b[34mL:   2 | P:  10 | CP01 | \u001b[0mKeywords must be consistently upper case.\n",
      "                       \u001b[34m| \u001b[0m[\u001b[30m\u001b[1mcapitalisation.keywords\u001b[0m]\n",
      "All Finished 📜 🎉!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sqlfluff lint sqlfluff_example.sql --dialect postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29c68a-2e54-4537-8a7c-d588182a4ada",
   "metadata": {},
   "source": [
    "To fix the style errors and inconsistencies found by the linter, we can run the `fix` command.\n",
    "\n",
    "```bash\n",
    "$ sqlfluff fix sqlfluff_example.sql --dialect postgres\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7099ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    c AS bar,\n",
      "    a + b AS foo\n",
      "FROM my_table\n"
     ]
    }
   ],
   "source": [
    "%cat sqlfluff_example.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccae380",
   "metadata": {},
   "source": [
    "Now, the SQL code is formatted and readable.\n",
    "\n",
    "[Link to SQLFluff](https://github.com/sqlfluff/sqlfluff).\n",
    "\n",
    "## PostgresML: Integrate Machine Learning with PostgreSQL\n",
    "\n",
    "If you want to seamlessly integrate machine learning models into your PostgreSQL database, use PostgresML. \n",
    "\n",
    "**Sentiment Analysis:**\n",
    "\n",
    "```sql\n",
    "SELECT pgml.transform(\n",
    "    task   => 'text-classification',\n",
    "    inputs => ARRAY[\n",
    "        'I love how amazingly simple ML has become!', \n",
    "        'I hate doing mundane and thankless tasks. ☹️'\n",
    "    ]\n",
    ") AS positivity;\n",
    "```\n",
    "\n",
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d5a59",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "                    positivity\n",
    "------------------------------------------------------\n",
    "[\n",
    "    {\"label\": \"POSITIVE\", \"score\": 0.9995759129524232}, \n",
    "    {\"label\": \"NEGATIVE\", \"score\": 0.9903519749641418}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844c6bb-1c83-4fab-8563-475ced95ab24",
   "metadata": {},
   "source": [
    "**Training a classification model**\n",
    "\n",
    "Training: \n",
    "\n",
    "```sql\n",
    "SELECT * FROM pgml.train(\n",
    "    'My Classification Project',\n",
    "    task => 'classification',\n",
    "    relation_name => 'pgml.digits',\n",
    "    y_column_name => 'target',\n",
    "    algorithm => 'xgboost',\n",
    "    hyperparams => '{\n",
    "        \"n_estimators\": 25\n",
    "    }'\n",
    ");\n",
    "```\n",
    "\n",
    "Inference:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    target,\n",
    "    pgml.predict('My Classification Project', image) AS prediction\n",
    "FROM pgml.digits\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "[Link to PostgresML](https://github.com/postgresml/postgresml).s\n",
    "\n",
    "## sql-metadata: Extract Components From a SQL Statement in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ba230",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sql-metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f085f",
   "metadata": {},
   "source": [
    "If you want to extract specific components of a SQL statement for downstream Python tasks, use sql_metdata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92904d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['foo.value', 'foo.id', 'bar.id']\n",
      "Tables: ['foo', 'bar']\n",
      "Columns dict: {'select': ['foo.value'], 'join': ['foo.id', 'bar.id']}\n",
      "Aliases: {'alias1': 'foo.value'}\n",
      "Limit: (10, 0)\n"
     ]
    }
   ],
   "source": [
    "from sql_metadata import Parser\n",
    "\n",
    "parsed_query = Parser(\n",
    "    \"SELECT foo.value as alias1 FROM foo JOIN bar ON foo.id = bar.id LIMIT 10\"\n",
    ")\n",
    "\n",
    "print(f\"Columns: {parsed_query.columns}\")\n",
    "print(f\"Tables: {parsed_query.tables}\")\n",
    "print(f\"Columns dict: {parsed_query.columns_dict}\")\n",
    "print(f\"Aliases: {parsed_query.columns_aliases}\")\n",
    "print(f\"Limit: {parsed_query.limit_and_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a96382",
   "metadata": {},
   "source": [
    "[Link to sql-metadata](https://github.com/macbre/sql-metadata).\n",
    "\n",
    "## Convert MySQL Queries to Spark SQL with SQLGlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d257860",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sqlglot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7f225",
   "metadata": {},
   "source": [
    "When migrating SQL queries from MySQL to Spark SQL, you may encounter differences in syntax. For example, MySQL uses the `IFNULL` function to handle null values, while Spark SQL uses the `COALESCE` function for the same purpose. Manually rewriting such queries can be tedious and error-prone.\n",
    "\n",
    "Consider the following MySQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72644346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a SQL query in MySQL dialect\n",
    "mysql_query = \"\"\"\n",
    "SELECT IFNULL(column_name, 'default_value') AS column_value \n",
    "FROM my_table;\n",
    "\"\"\"\n",
    "\n",
    "# This query uses MySQL-specific syntax (e.g., IFNULL function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ad01f",
   "metadata": {},
   "source": [
    "In this query, the `IFNULL` function replaces null values in `column_name` with `'default_value'`. However, Spark SQL uses the `COALESCE` function for this operation.\n",
    "\n",
    "SQLGlot can automate this conversion process, making it seamless to adapt queries for Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f46784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COALESCE(column_name, 'default_value') AS column_value FROM my_table\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "\n",
    "# Transpile the MySQL query to Spark SQL dialect\n",
    "spark_sql_query = sqlglot.transpile(mysql_query, read=\"mysql\", write=\"spark\")[0]\n",
    "\n",
    "print(spark_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e7f07",
   "metadata": {},
   "source": [
    "Here, SQLGlot automatically converts the MySQL `IFNULL` function to Spark SQL's `COALESCE` function. This ensures compatibility and saves time when migrating queries between MySQL and Spark SQL.\n",
    "\n",
    "[Link to SQLGlot](https://github.com/tobymao/sqlglot).\n",
    "\n",
    "## SQliteDict: Reducing SQLite Complexity with Dictionary-Style Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7894c33-4dab-4990-8d71-a611e1a82fc7",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install sqlitedict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad8730-b06f-49a1-894b-e34218f2fe31",
   "metadata": {},
   "source": [
    "Writing data to SQLite directly and reading it back requires verbose SQL statements, schema definitions, and type handling, which can be tedious when storing complex Python objects or making frequent changes results in complex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f61565c-724c-47ca-a675-cd4aa93a594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "products_to_update = [\n",
    "    (\"P1\", \"Laptop\", 999.99, 50),\n",
    "    (\"P2\", \"Mouse\", 29.99, 100),\n",
    "    (\"P3\", \"Keyboard\", 59.99, 75),\n",
    "]\n",
    "\n",
    "with sqlite3.connect(\"example.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS products \n",
    "                     (id TEXT PRIMARY KEY, name TEXT, price REAL, stock INTEGER)\"\"\"\n",
    "    )\n",
    "    cursor.executemany(\n",
    "        \"\"\"INSERT OR REPLACE INTO products (id, name, price, stock) \n",
    "                         VALUES (?, ?, ?, ?)\"\"\",\n",
    "        products_to_update,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a73a8c1-21ce-4531-9b5d-50c4b3ffc24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1={'name': 'Laptop', 'price': 999.99, 'stock': 50}\n",
      "P2={'name': 'Mouse', 'price': 29.99, 'stock': 100}\n",
      "P3={'name': 'Keyboard', 'price': 59.99, 'stock': 75}\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(\"example.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT id, name, price, stock FROM products\")\n",
    "    for row in cursor.fetchall():\n",
    "        product_data = {\"name\": row[1], \"price\": row[2], \"stock\": row[3]}\n",
    "        print(f\"{row[0]}={product_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b3728-8e04-4d48-92b3-8927a86e2e6c",
   "metadata": {},
   "source": [
    "You can use SqliteDict to handle all the SQL and serialization complexity with a familiar dictionary interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df941862-a501-4768-a1c9-43088cc4b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "\n",
    "products_to_update = {\n",
    "    \"P1\": {\"name\": \"Laptop\", \"price\": 999.99, \"stock\": 50},\n",
    "    \"P2\": {\"name\": \"Mouse\", \"price\": 29.99, \"stock\": 100},\n",
    "    \"P3\": {\"name\": \"Keyboard\", \"price\": 59.99, \"stock\": 75},\n",
    "}\n",
    "\n",
    "with SqliteDict(\"example2.db\") as db:\n",
    "    # Update multiple records in a batch\n",
    "    for product_id, product_data in products_to_update.items():\n",
    "        db[product_id] = product_data\n",
    "\n",
    "    # Single commit for all updates\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21cc3d53-e01d-45ac-b46c-7d7f4e79a075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1={'name': 'Laptop', 'price': 999.99, 'stock': 50}\n",
      "P2={'name': 'Mouse', 'price': 29.99, 'stock': 100}\n",
      "P3={'name': 'Keyboard', 'price': 59.99, 'stock': 75}\n"
     ]
    }
   ],
   "source": [
    "with SqliteDict(\"example2.db\") as db:\n",
    "    for key, item in db.items():\n",
    "        print(f\"{key}={item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a4fd4-86cc-458f-89f2-2b2d027504d5",
   "metadata": {},
   "source": [
    "The example shows how SqliteDict eliminates the need for explicit SQL statements, cursor management, and serialization. The tool handles schema creation, data type conversion, and connection management internally, while providing a Pythonic interface. This is particularly useful when you need to frequently store and retrieve complex Python objects without dealing with the underlying database complexity.\n",
    "\n",
    "[Link to SqliteDict](https://github.com/piskvorky/sqlitedict)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
