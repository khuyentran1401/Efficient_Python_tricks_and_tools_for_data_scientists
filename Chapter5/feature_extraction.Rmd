---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python tags=c("remove-cell")}
import warnings

warnings.filterwarnings("ignore")
```

# Feature Extraction


## distfit: Find The Best Theoretical Distribution For Your Data

```{python tags=c("hide-cell")}
# !pip install distfit
```

If you're looking to identify the best theoretical distribution for your data in Python, try distfit. It allows you to fit and compare multiple distributions, identifying the best match for your dataset.

```{python}
import numpy as np
from distfit import distfit

X = np.random.normal(0, 3, 1000)

## Initialize model
dist = distfit()

## Find best theoretical distribution for empirical data X
distribution = dist.fit_transform(X)
dist.plot()
```

Beyond finding the optimal distribution, `distfit` can also help identify outliers based on deviation from the fitted distribution.


[Link to distfit](https://github.com/erdogant/distfit).


## Geopy: Extract Location Based on Python String

```{python tags=c("hide-cell")}
# !pip install geopy
```

`Geopy` simplifies the process of extracting geospatial information from location strings. With just a few lines of code, you can obtain the coordinates of addresses globally.

```{python}
from geopy.geocoders import Nominatim

geolocator = Nominatim(user_agent="find_location")
location = geolocator.geocode("30 North Circle Drive")
```

To get detailed information about the location:

```{python}
location.address
```

You can also extract latitude and longitude:

```{python}
location.latitude, location.longitude
```

[Link to Geopy](https://github.com/geopy/geopy).


## fastaiâ€™s cont_cat_split: Separate Continuous and Categorical Variables

```{python tags=c("hide-cell")}
# !pip install fastai
```

Fastai's `cont_cat_split` method helps you automatically separate continuous and categorical columns in a DataFrame based on their cardinality.

```{python}
import pandas as pd
from fastai.tabular.core import cont_cat_split

df = pd.DataFrame(
    {
        "col1": [1, 2, 3, 4, 5],
        "col2": ["a", "b", "c", "d", "e"],
        "col3": [1.0, 2.0, 3.0, 4.0, 5.0],
    }
)

cont_names, cat_names = cont_cat_split(df)
print("Continuous columns:", cont_names)
print("Categorical columns:", cat_names)
```

```{python}
cont_names, cat_names = cont_cat_split(df, max_card=3)
print("Continuous columns:", cont_names)
print("Categorical columns:", cat_names)
```

[Link to the documentation](https://docs.fast.ai/tabular.core.html).


## Formulaic: Write Clear Feature Engineering Code

```{python tags=c("hide-cell")}
# !pip install formulaic
```

Feature engineering, especially for statistical models, often requires manually creating interaction terms, polynomial transformations, or encoding categorical variables. This can quickly become verbose and error-prone when using libraries like pandas or NumPy:

```{python}
df = pd.DataFrame({"x": ["A", "B", "C"], "z": [0.3, 0.1, 0.2], "y": [0, 1, 2]})
print(df)
```

```{python}
import numpy as np
import pandas as pd

## Sample dataset
df = pd.DataFrame({"x": ["A", "B", "C"], "z": [0.3, 0.1, 0.2], "y": [0, 1, 2]})

## Manual feature engineering
df["x_B"] = (df["x"] == "B").astype(int)
df["x_C"] = (df["x"] == "C").astype(int)
df["z_squared"] = df["z"] ** 2

print(df)
```

Manually encoding categorical variables and creating polynomial features leads to repetitive code and increases the likelihood of errors, especially in larger datasets or more complex models.

Formulaic streamlines feature engineering by allowing you to define transformations and relationships in a single formula string, inspired by Wilkinson formulas.

```{python}
from formulaic import Formula

## Define a formula for feature engineering
formula = "y ~ x + I(z**2)"

## Apply the formula to get the response and design matrices
y, X = Formula(formula).get_model_matrix(df)

print("Response (y):")
print(y)

print("\nDesign Matrix (X):")
print(X)
```

In this example:

- `"y ~ x + I(z**2)"`: The formula specifies that `y` is the response variable, `x` is a categorical predictor (automatically one-hot encoded), and `z**2` represents the square of `z`.
- `Formula.get_model_matrix()`: Automatically generates the response (`y`) and design matrix (`X`) based on the formula.

The output demonstrates how Formulaic automatically handles categorical encoding, interaction terms, and polynomial transformations, significantly simplifying feature engineering.

[Link to Formulaic](https://github.com/matthewwardrop/formulaic)


## yarl: Create and Extract Elements from a URL Using Python

```{python tags=c("hide-cell")}
# !pip install yarl
```

`yarl` makes URL parsing and creation easy. You can extract elements like host, path, and query from a URL or construct new URLs.

```{python}
from yarl import URL

url = URL("https://github.com/search?q=data+science")
url
```

```{python}
print(url.host)
```

```{python}
print(url.path)
```

```{python}
print(url.query_string)
```

You can also build new URLs:

```{python}
# Create a URL

url = URL.build(
    scheme="https",
    host="github.com",
    path="/search",
    query={"p": 2, "q": "data science"},
)

print(url)
```

```{python}
## Replace the query

print(url.with_query({"q": "python"}))
```

```{python}
## Replace the path

new_path = url.with_path("khuyentran1401/Data-science")
print(new_path)
```

```{python}
## Update the fragment

print(new_path.with_fragment("contents"))
```

[Link to yarl](https://github.com/aio-libs/yarl).


## Pigeon: Quickly Annotate Your Data on Jupyter Notebook

```{python tags=c("hide-cell")}
# !pip install pigeon-jupyter
```

For fast data annotation within Jupyter Notebooks, use `Pigeon`. This tool allows you to label data interactively by selecting from predefined options.

```{python}
from pigeon import annotate

annotations = annotate(
    ["The service is terrible", "I will definitely come here again"],
    options=["positive", "negative"],
)
```

```{python}
annotations
```

![](../img/pigeon_demo.gif)


After labeling all your data, you can get the examples along with their labels by calling `annotations`.


[Link to Pigeon](https://github.com/agermanidis/pigeon)


## probablepeople: Parse Unstructured Names Into Structured Components

```{python tags=c("hide-cell")}
# !pip install probablepeople
```

`probablepeople` helps you parse unstructured names into structured components like first names, surnames, and company names.

```{python}
import probablepeople as pp

pp.parse("Mr. Owen Harris II")
```

```{python}
pp.parse("Kate & John Cumings")
```

```{python}
pp.parse("Prefect Technologies, Inc")
```

[Link to probablepeople](https://github.com/datamade/probablepeople).


## Extract PDF Text Precisely with PyPDF

```{python tags=c("hide-cell")}
# !pip install fpdf pypdf
```

Extracting text from PDFs often results in including undesired elements like headers, footers, page numbers, or small captions due to the lack of semantic layers in PDF files.

PyPDF can split, merge, crop, transform, and manipulate PDFs. It also supports extracting text and metadata from PDF files, making it a powerful tool for PDF processing.

To demonstrate this, start with creating an example PDF:

```{python}
from fpdf import FPDF
from pathlib import Path

# Create a duck-themed PDF with headers and body text
class DuckPDF(FPDF):
    def add_header(self, text):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, text, ln=True)

    def add_body(self, text):
        self.set_font("Arial", "", 9)
        self.multi_cell(0, 10, text)
        self.ln(5)

# Create and fill the PDF
pdf = DuckPDF()
pdf.add_page()
pdf.add_header("DUCK BIOLOGY")
pdf.add_body("Mallards are common ducks found in North America.\nThey have green heads and a yellow bill.")
pdf.add_header("Duck Habitats")
pdf.add_body("Ducks live near ponds, lakes, and marshes.\nThey build nests near the water and eat aquatic plants.")

# Save the PDF
duck_pdf_path = Path("duck_biology.pdf")
pdf.output(str(duck_pdf_path))
```

```{python}
from PyPDF2 import PdfReader

## Extracting text without filtering headers, footers, or specific elements
reader = PdfReader("duck_biology.pdf")
page = reader.pages[0]
text = page.extract_text()
print(text)  # Outputs all text, including headers, footers, and other elements
```

In the code above, the text extraction results in capturing all textual elements on the page, including headers, footers, and possibly formatting artifacts. This makes it challenging to focus only on the main content.

Using the `visitor_text` feature of PyPDF, you can precisely control the parts of the text to extract by applying custom logic, such as filtering out headers, footers, or small-font elements.


The code snippet below demonstrates how to filter out small-font text (e.g., headers, footers, or captions) by using a visitor function in the `extract_text` method.

```{python}
from PyPDF2 import PdfReader

## Threshold to consider "small" text
SMALL_FONT_THRESHOLD = 10

## Prepare a list to store the filtered text
parts = []


## Visitor function to filter text based on font size
def visitor_body(text, cm, tm, font_dict, font_size):
    if font_size < SMALL_FONT_THRESHOLD:
        parts.append(text)
```

Explanation of parameters in the visitor function:
- `text`: This is the actual text string from the PDF that the visitor function processes. It contains the specific snippet of text that is currently being evaluated.
- `cm` (current transformation matrix): This matrix describes how the text is positioned and scaled on the page. For example, `cm[4]` and `cm[5]` represent the horizontal and vertical positions of the text, respectively.
- `tm` (text matrix): This describes the transformation applied in the text coordinate space. It is used internally to map text coordinates to the user space.
- `font_dict`: This is a dictionary containing font metadata (e.g., font type, style). For instance, it may include keys like `/BaseFont` with values such as `/Arial,Bold`.
- `font_size`: The font size of the current text snippet being processed. It is measured in text coordinate space and can be used to identify small text such as footers or captions.


Using the `extract_text` method with the `visitor_body` function allows us to extract only the desired text elements.

```{python}
reader = PdfReader("duck_biology.pdf")
page = reader.pages[0]
page.extract_text(visitor_text=visitor_body)

## Combine all filtered parts into a single string
text_body = "".join(parts)

print(text_body)
```

The extracted text is now free of page numbers or small-font elements like headers and footers, providing a cleaner and more focused output for further analysis.

[Link to PyPDF](https://github.com/py-pdf/pypdf).
